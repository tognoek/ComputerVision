{"cells":[{"cell_type":"code","execution_count":12,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-24T17:34:27.699300Z","iopub.status.busy":"2024-10-24T17:34:27.698765Z","iopub.status.idle":"2024-10-24T17:34:27.706228Z","shell.execute_reply":"2024-10-24T17:34:27.704764Z","shell.execute_reply.started":"2024-10-24T17:34:27.699250Z"},"trusted":true},"outputs":[],"source":["import pandas as pd # type: ignore\n","import numpy as np # type: ignore\n","from sklearn.model_selection import train_test_split # type: ignore\n","from sklearn.preprocessing import StandardScaler # type: ignore"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T17:34:27.709187Z","iopub.status.busy":"2024-10-24T17:34:27.708675Z","iopub.status.idle":"2024-10-24T17:34:27.720375Z","shell.execute_reply":"2024-10-24T17:34:27.719135Z","shell.execute_reply.started":"2024-10-24T17:34:27.709130Z"},"trusted":true},"outputs":[],"source":["# Đặt seed để tái lập ngẫu nhiên\n","np.random.seed(2904)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["path = './data'"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T17:34:27.722960Z","iopub.status.busy":"2024-10-24T17:34:27.722098Z","iopub.status.idle":"2024-10-24T17:34:27.733047Z","shell.execute_reply":"2024-10-24T17:34:27.731679Z","shell.execute_reply.started":"2024-10-24T17:34:27.722900Z"},"trusted":true},"outputs":[],"source":["class MeanSquaredError:\n","    def forward(self, y_pred, y_true):\n","        self.pred = y_pred\n","        self.true = y_true\n","        return np.mean((y_pred - y_true) ** 2)\n","\n","    def backward(self):\n","        return 2 * (self.pred - self.true) / self.true.size"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T17:34:27.735798Z","iopub.status.busy":"2024-10-24T17:34:27.734664Z","iopub.status.idle":"2024-10-24T17:34:27.747111Z","shell.execute_reply":"2024-10-24T17:34:27.745876Z","shell.execute_reply.started":"2024-10-24T17:34:27.735743Z"},"trusted":true},"outputs":[],"source":["class Linear:\n","    def __init__(self, input_dim, output_dim, regularization, learning_rate):\n","        self.W = np.random.randn(input_dim, output_dim) * 0.01  \n","        self.b = np.zeros((1, output_dim)) \n","        self.reg = regularization  \n","        self.learning_rate = learning_rate\n","\n","    def forward(self, X):\n","        self.X = X  \n","        return X @ self.W + self.b\n","\n","    def backward(self, dLoss):\n","        m = self.X.shape[0]  \n","        dW = (self.X.T @ dLoss) / m + self.reg * self.W  \n","        db = np.sum(dLoss, axis=0, keepdims=True) / m \n","        dX = dLoss @ self.W.T  \n","        self.W -= self.learning_rate * dW\n","        self.b -= self.learning_rate * db\n","        return dX, dW, db"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T17:34:27.754097Z","iopub.status.busy":"2024-10-24T17:34:27.753207Z","iopub.status.idle":"2024-10-24T17:34:27.761579Z","shell.execute_reply":"2024-10-24T17:34:27.760161Z","shell.execute_reply.started":"2024-10-24T17:34:27.754038Z"},"trusted":true},"outputs":[],"source":["class ReLU:\n","    def forward(self, X):\n","        self.X = X\n","        return np.maximum(0, X)\n","\n","    def backward(self, dLoss):\n","        return dLoss * (self.X > 0)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T17:34:27.763799Z","iopub.status.busy":"2024-10-24T17:34:27.763279Z","iopub.status.idle":"2024-10-24T17:34:27.779261Z","shell.execute_reply":"2024-10-24T17:34:27.777877Z","shell.execute_reply.started":"2024-10-24T17:34:27.763740Z"},"trusted":true},"outputs":[],"source":["class LinearAndReLU:\n","    def __init__(self, input_dim, output_dim, regularization, learning_rate):\n","        self.linear = Linear(input_dim, output_dim, regularization, learning_rate)\n","        self.relu = ReLU()\n","\n","    def forward(self, X):\n","        self.X = X\n","        return self.relu.forward(self.linear.forward(X))\n","\n","    def backward(self, dLoss):\n","        dLoss = self.relu.backward(dLoss)\n","        return self.linear.backward(dLoss)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T17:34:27.782092Z","iopub.status.busy":"2024-10-24T17:34:27.781446Z","iopub.status.idle":"2024-10-24T17:34:37.868726Z","shell.execute_reply":"2024-10-24T17:34:37.867505Z","shell.execute_reply.started":"2024-10-24T17:34:27.782032Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_60912/1310717537.py:23: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n","  X_train = X_train.applymap(extract_value_after_space)\n","/tmp/ipykernel_60912/1310717537.py:24: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n","  y_train = y_train.applymap(extract_value_after_space)\n","/tmp/ipykernel_60912/1310717537.py:65: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n","  X_test = X_test.applymap(extract_value_after_space)\n"]},{"name":"stdout","output_type":"stream","text":["Xong rồi nè bạn!!!\n"]}],"source":["def normalize(X):\n","    X = np.array(X, dtype=np.float64)  \n","    mean = np.mean(X, axis=0) \n","    std = np.std(X, axis=0)   \n","    return (X - mean) / std\n","\n","def divide_by_100(X):\n","    return np.array(X, dtype=np.float64) / 100\n","\n","X_train = pd.read_csv(f'{path}/X_train.csv', low_memory=False)\n","y_train = pd.read_csv(f'{path}/Y_train.csv', low_memory=False)\n","if 'tradeTime' in X_train.columns:\n","    X_train['tradeTime'] = pd.to_datetime(X_train['tradeTime'], errors='coerce')\n","    X_train['construction_year'] = X_train['tradeTime'].dt.year\n","    X_train['construction_month'] = X_train['tradeTime'].dt.month\n","    X_train['construction_day'] = X_train['tradeTime'].dt.day\n","    X_train.drop(columns=['tradeTime'], inplace=True)\n","def extract_value_after_space(x):\n","    if isinstance(x, str):\n","        parts = x.split(' ')\n","        return parts[-1] if len(parts) > 1 else x\n","    return x\n","X_train = X_train.applymap(extract_value_after_space)\n","y_train = y_train.applymap(extract_value_after_space)\n","invalid_values = ['#NAME?', '未知', '混合结构', '钢混结构']\n","X_train.replace(invalid_values, np.nan, inplace=True)\n","y_train.replace(invalid_values, np.nan, inplace=True)\n","\n","X_train = X_train.apply(pd.to_numeric, errors='coerce')\n","y_train = y_train.apply(pd.to_numeric, errors='coerce')\n","\n","X_train.fillna(X_train.mean(), inplace=True)\n","y_train.fillna(y_train.mean(), inplace=True)\n","\n","train_data = X_train.merge(y_train, on='ID', how='inner')\n","X = train_data.drop(columns=['ID', 'TARGET'])\n","y = train_data[['TARGET']]\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","\n","X_train = np.array(X_train)  \n","y_train = np.array(y_train)  \n","X_val = np.array(X_val)      \n","y_val = np.array(y_val)  \n","\n","# Bật cái bên dưới để làm cho dữ liệu được chia dạng bình quân nha ní\n","# X_train = normalize(X_train)\n","# X_val = normalize(X_val)  \n","y_train = divide_by_100(y_train)\n","y_val = divide_by_100(y_val)   \n","\n","X_test = pd.read_csv(f'{path}/X_test.csv', low_memory=False)\n","\n","if 'tradeTime' in X_test.columns:\n","    X_test['tradeTime'] = pd.to_datetime(X_test['tradeTime'], errors='coerce')\n","    X_test['construction_year'] = X_test['tradeTime'].dt.year\n","    X_test['construction_month'] = X_test['tradeTime'].dt.month\n","    X_test['construction_day'] = X_test['tradeTime'].dt.day\n","    X_test.drop(columns=['tradeTime'], inplace=True)\n","    \n","X_test = X_test.applymap(extract_value_after_space)\n","X_test.replace(invalid_values, np.nan, inplace=True)\n","X_test = X_test.apply(pd.to_numeric, errors='coerce')\n","X_test.fillna(X_test.mean(), inplace=True)\n","\n","X_test = np.array(X_test)\n","X_test = normalize(X_test)\n","\n","print('Xong rồi nè bạn!!!')"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T17:34:37.871355Z","iopub.status.busy":"2024-10-24T17:34:37.870866Z","iopub.status.idle":"2024-10-24T17:34:37.898597Z","shell.execute_reply":"2024-10-24T17:34:37.896904Z","shell.execute_reply.started":"2024-10-24T17:34:37.871302Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Xong rồi nè bạn!!!\n"]}],"source":["class NeuralNetwork:\n","    def __init__(self, input_dim, hidden_dims, output_dim, regularization=0.01, learning_rate=1e-3):\n","        dimensions = [input_dim] + hidden_dims\n","        self.learning_rate = learning_rate;\n","        self.layers = []\n","        for i in range(1, len(dimensions)):\n","            self.layers.append(LinearAndReLU(dimensions[i-1], dimensions[i], regularization, learning_rate))\n","        self.final_layer = Linear(dimensions[-1], output_dim, regularization, learning_rate)\n","        self.fun_loss = MeanSquaredError()\n","        self.best_weights = None\n","        self.best_cost = float('inf')\n","\n","    def forward(self, X, y=None, training=True):\n","        hidden = X\n","        for layer in self.layers:\n","            hidden = layer.forward(hidden)\n","        scores = self.final_layer.forward(hidden)\n","        cost = self.fun_loss.forward(scores, y) if y is not None else None\n","        \n","        if not training:\n","            return scores\n","        \n","        dLoss = self.fun_loss.backward() if y is not None else None\n","        dLoss, _, _ = self.final_layer.backward(dLoss) if y is not None else (None, None, None)\n","        \n","        for i in range(len(self.layers) - 1, -1, -1):\n","            dLoss, _, _ = self.layers[i].backward(dLoss)\n","        \n","        return cost\n","\n","    def predict(self, X):\n","        return self.forward(X, training=False)\n","    \n","    def update_learning_rate(self, learning_rate):\n","        for layer in self.layers:\n","            layer.learning_rate = learning_rate\n","        self.final_layer.learning_rate = learning_rate\n","\n","    def train(self, X_train, y_train, epochs, batch_size):\n","        for epoch in range(epochs):\n","            indices = np.arange(X_train.shape[0])\n","            np.random.shuffle(indices)\n","            X_train = X_train[indices]\n","            y_train = y_train[indices]\n","\n","            for i in range(0, X_train.shape[0], batch_size):\n","                X_batch = X_train[i:i + batch_size]\n","                y_batch = y_train[i:i + batch_size]\n","                self.forward(X_batch, y_batch)\n","\n","            if (epoch + 1) % 10 == 0:\n","                train_cost = self.forward(X_train, y_train)\n","                print(f\"Epoch {epoch + 1}/{epochs}, Training Cost: {train_cost:.4f}\")\n","\n","                if train_cost < self.best_cost:\n","                    self.best_cost = train_cost\n","                    self.best_weights = {\n","                        'W': [layer.linear.W.copy() for layer in self.layers] + [self.final_layer.W.copy()],\n","                        'b': [layer.linear.b.copy() for layer in self.layers] + [self.final_layer.b.copy()]\n","                    }\n","                \n","            if (epoch + 1) % 30 == 0:\n","                self.learning_rate = self.learning_rate * 0.99\n","                self.update_learning_rate(self.learning_rate)\n","\n","    def load_best_weights(self):\n","        if self.best_weights is not None:\n","            for i, layer in enumerate(self.layers):\n","                layer.linear.W = self.best_weights['W'][i].copy()\n","                layer.linear.b = self.best_weights['b'][i].copy()\n","            self.final_layer.W = self.best_weights['W'][-1].copy()\n","            self.final_layer.b = self.best_weights['b'][-1].copy()   \n","\n","    def save_best_weights_to_csv(self, url):\n","        data = {\n","            'Layer': [],\n","            'Weights': [],\n","            'Bias': []\n","        }\n","\n","        for i, layer in enumerate(self.layers):\n","            data['Layer'].append(f'Layer {i + 1}')\n","            data['Weights'].append(layer.linear.W.flatten())\n","            data['Bias'].append(layer.linear.b.flatten())\n","\n","        data['Layer'].append('Final Layer')\n","        data['Weights'].append(self.final_layer.W.flatten())\n","        data['Bias'].append(self.final_layer.b.flatten())\n","\n","        df = pd.DataFrame(data)\n","        df.to_csv(url, index=False)\n","print('Xong rồi nè bạn!!!')"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-10-24T17:51:43.301851Z","iopub.status.busy":"2024-10-24T17:51:43.301371Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 10/200, Training Cost: 0.3719\n","Epoch 20/200, Training Cost: 0.3713\n","Epoch 30/200, Training Cost: 0.4174\n","Epoch 40/200, Training Cost: 0.3913\n","Epoch 50/200, Training Cost: 0.3793\n","Epoch 60/200, Training Cost: 0.3874\n","Epoch 70/200, Training Cost: 0.3998\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m net \u001b[38;5;241m=\u001b[39m NeuralNetwork(input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m22\u001b[39m, hidden_dims\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m60\u001b[39m], output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, regularization\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Huấn luyện mạng\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Dự đoán trên dữ liệu kiểm tra\u001b[39;00m\n\u001b[1;32m      8\u001b[0m y_test_predicted \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mpredict(X_test)\n","Cell \u001b[0;32mIn[20], line 49\u001b[0m, in \u001b[0;36mNeuralNetwork.train\u001b[0;34m(self, X_train, y_train, epochs, batch_size)\u001b[0m\n\u001b[1;32m     47\u001b[0m     X_batch \u001b[38;5;241m=\u001b[39m X_train[i:i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m     48\u001b[0m     y_batch \u001b[38;5;241m=\u001b[39m y_train[i:i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     52\u001b[0m     train_cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(X_train, y_train)\n","Cell \u001b[0;32mIn[20], line 27\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, X, y, training)\u001b[0m\n\u001b[1;32m     24\u001b[0m dLoss, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer\u001b[38;5;241m.\u001b[39mbackward(dLoss) \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 27\u001b[0m     dLoss, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdLoss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cost\n","Cell \u001b[0;32mIn[18], line 12\u001b[0m, in \u001b[0;36mLinearAndReLU.backward\u001b[0;34m(self, dLoss)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, dLoss):\n\u001b[1;32m     11\u001b[0m     dLoss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu\u001b[38;5;241m.\u001b[39mbackward(dLoss)\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdLoss\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[16], line 15\u001b[0m, in \u001b[0;36mLinear.backward\u001b[0;34m(self, dLoss)\u001b[0m\n\u001b[1;32m     13\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]  \n\u001b[1;32m     14\u001b[0m dW \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m dLoss) \u001b[38;5;241m/\u001b[39m m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreg \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW  \n\u001b[0;32m---> 15\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdLoss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m m \n\u001b[1;32m     16\u001b[0m dX \u001b[38;5;241m=\u001b[39m dLoss \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW\u001b[38;5;241m.\u001b[39mT  \n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m dW\n","File \u001b[0;32m~/Code/Python/ComputerVision/Ipynb/.venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:2344\u001b[0m, in \u001b[0;36m_sum_dispatcher\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2338\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing `min` or `max` keyword argument when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2339\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`a_min` and `a_max` are provided is forbidden.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m'\u001b[39m, a_min, a_max, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 2344\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2345\u001b[0m                     initial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[1;32m   2349\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_sum_dispatcher)\n\u001b[1;32m   2350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2351\u001b[0m         initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Sử dụng mạng\n","net = NeuralNetwork(input_dim=22, hidden_dims=[60, 60], output_dim=1, regularization=0.01, learning_rate=1e-3)\n","\n","# Huấn luyện mạng\n","net.train(X_train, y_train, epochs=200, batch_size=2)\n","\n","# Dự đoán trên dữ liệu kiểm tra\n","y_test_predicted = net.predict(X_test)\n","\n","results = pd.DataFrame({'TARGET': y_test_predicted.flatten()})\n","results['ID'] = range(0, len(results)) \n","results = results[['ID', 'TARGET']]\n","results['TARGET'] = (results['TARGET'] * 100).round().astype(int)\n","\n","path_out = './out'\n","name = 'tognoek_60_60_'\n","\n","results.to_csv(f'{path_out}/{name}{(net.best_cost * 100000):.0f}.csv', index=False)\n","net.save_best_weights_to_csv(f'{path_out}/{name}{(net.best_cost * 100000):.0f}_w.csv')\n","\n","print(f'{path_out}/{name}{(net.best_cost * 100000):.0f}')\n","print('Đã xong rồi !!!')"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5942037,"sourceId":9713631,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"}},"nbformat":4,"nbformat_minor":4}
